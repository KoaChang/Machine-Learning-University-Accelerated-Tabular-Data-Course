{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Machine Learning Accelerator - Tabular Data - Lecture 3</a>\n",
    "\n",
    "## Final Project:  Neural Networks and AutoML\n",
    "\n",
    "You have more choices for today. Build a Neural Network with PyTorch or use [AutoGluon](https://auto.gluon.ai/stable/tutorials/tabular_prediction/index.html) to predict the __label__ field (substitute or not substitute) of the Amazon product substitute dataset. \n",
    "__Note: If you use Autogluon, you don't need to follow the steps in this notebook. Just refer to the Autogluon notebook in the class or [this tutorial](https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-quickstart.html)__.\n",
    "\n",
    "### Final Project Problem: Product Substitute Prediction\n",
    "\n",
    "__Problem Definition__:\n",
    "Given a pair of products, (A, B), we say that B is a \"substitute\" for A if a customer would buy B in place of A -- say, if A were out of stock.\n",
    "\n",
    "The goal of this project is to predict a substitute relationship between pairs of products. Complete the tasks in this notebook and submit your network's predictions as a CSV file to the leaderboard: __https://mlu.corp.amazon.com/contests/redirect/35__\n",
    "\n",
    "1. <a href=\"#1\">Read the datasets</a> (Given) \n",
    "2. <a href=\"#2\">Data Processing</a> (Implement)\n",
    "    * <a href=\"#21\">Exploratory Data Analysis</a>\n",
    "    * <a href=\"#22\">Select features to build the model</a> (Suggested)\n",
    "    * <a href=\"#23\">Train - Validation - Test Datasets</a>\n",
    "    * <a href=\"#24\">Data Processing with Pipeline and ColumnTransformer</a>\n",
    "3. <a href=\"#3\">Network Training and Validation on the Training Dataset</a> (Implement)\n",
    "4. <a href=\"#4\">Make Predictions on the Test Dataset</a> (Implement)\n",
    "5. <a href=\"#4\">Write the Test Predictions to a CSV file</a> (Given)\n",
    "\n",
    "\n",
    "__Datasets and Files:__\n",
    "\n",
    "\n",
    "* __training.csv__: Training data with product pair features and corresponding labels::\n",
    "> - `ID:` ID of the record\n",
    "> - `label:` Tells whether the key and candidate products are substitutes (1) or not (0).\n",
    "> - `key_asin ...:` Key product ASIN features \n",
    "> - `cand_asin ...:` Candidate product ASIN features \n",
    "\n",
    "\n",
    "* __public_test_features.csv__: Test data with product pairs features __without__ labels::\n",
    "> - `ID:` ID of the record\n",
    "> - `key_asin ...:` Key product ASIN features \n",
    "> - `cand_asin ...:` Candidate product ASIN features \n",
    "\n",
    "\n",
    "* __metadata-dataset.xlsx__: Provides detailed information about all key_ and cand_ columns in the training and test sets. Try to select some useful features to include in the model, as not all of them are suitable. `|Region Id|MarketPlace Id|ASIN|Binding Code|binding_description|brand_code|case_pack_quantity|, ...`\n",
    "\n",
    "\n",
    "* __Sample submission file:__ You can see a sample file: sample-submission.csv under data/final_project folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Read the datasets</a> (Given)\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Files for the final project are training and test data files, a sample submission file and a metadata file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we read the __training__ and __test__ datasets into dataframes, using [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html). This library allows us to read and manipulate our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset is: (36803, 228)\n",
      "The shape of the test dataset is: (15774, 227)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "  \n",
    "training_data = pd.read_csv('../../data/final_project/training.csv')\n",
    "test_data = pd.read_csv('../../data/final_project/public_test_features.csv')\n",
    "\n",
    "print('The shape of the training dataset is:', training_data.shape)\n",
    "print('The shape of the test dataset is:', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Data Processing</a> (Implement)\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "### 2.1 <a name=\"21\">Exploratory Data Analysis</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We look at number of rows, columns, and some simple statistics of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>key_Region Id</th>\n",
       "      <th>key_MarketPlace Id</th>\n",
       "      <th>key_ASIN</th>\n",
       "      <th>key_Binding Code</th>\n",
       "      <th>key_binding_description</th>\n",
       "      <th>key_brand_code</th>\n",
       "      <th>key_case_pack_quantity</th>\n",
       "      <th>key_classification_code</th>\n",
       "      <th>...</th>\n",
       "      <th>cand_pkg_weight</th>\n",
       "      <th>cand_pkg_weight_uom</th>\n",
       "      <th>cand_pkg_width</th>\n",
       "      <th>cand_release_date_embargo_level</th>\n",
       "      <th>cand_dw_creation_date</th>\n",
       "      <th>cand_dw_last_updated</th>\n",
       "      <th>cand_is_deleted</th>\n",
       "      <th>cand_last_updated</th>\n",
       "      <th>cand_version</th>\n",
       "      <th>cand_external_testing_certification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B00YCZ6IKA</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>NICLW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529104</td>\n",
       "      <td>pounds</td>\n",
       "      <td>5.118110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-Apr-13</td>\n",
       "      <td>14-Oct-17</td>\n",
       "      <td>N</td>\n",
       "      <td>13-Oct-17</td>\n",
       "      <td>2867</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3581</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B00U25WT7A</td>\n",
       "      <td>office_product</td>\n",
       "      <td>Office Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>pounds</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19-May-16</td>\n",
       "      <td>21-Mar-18</td>\n",
       "      <td>N</td>\n",
       "      <td>20-Mar-18</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B011BZ3GXU</td>\n",
       "      <td>consumer_electronics</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654773</td>\n",
       "      <td>pounds</td>\n",
       "      <td>3.937008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Dec-15</td>\n",
       "      <td>16-Feb-18</td>\n",
       "      <td>N</td>\n",
       "      <td>15-Feb-18</td>\n",
       "      <td>1532</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B0089XDG3I</td>\n",
       "      <td>pc</td>\n",
       "      <td>Personal Computers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>...</td>\n",
       "      <td>3.549442</td>\n",
       "      <td>pounds</td>\n",
       "      <td>10.314961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19-Oct-12</td>\n",
       "      <td>15-Feb-18</td>\n",
       "      <td>N</td>\n",
       "      <td>14-Feb-18</td>\n",
       "      <td>13964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14628</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B014UTSBZW</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>ZUKC7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>base_product</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396832</td>\n",
       "      <td>pounds</td>\n",
       "      <td>5.196850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26-Jul-12</td>\n",
       "      <td>9-Mar-18</td>\n",
       "      <td>N</td>\n",
       "      <td>9-Mar-18</td>\n",
       "      <td>1253</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label  key_Region Id  key_MarketPlace Id    key_ASIN  \\\n",
       "0  34016      0              1                   1  B00YCZ6IKA   \n",
       "1   3581      0              1                   1  B00U25WT7A   \n",
       "2  36025      1              1                   1  B011BZ3GXU   \n",
       "3  42061      1              1                   1  B0089XDG3I   \n",
       "4  14628      1              1                   1  B014UTSBZW   \n",
       "\n",
       "       key_Binding Code key_binding_description key_brand_code  \\\n",
       "0               kitchen                 Kitchen          NICLW   \n",
       "1        office_product          Office Product            NaN   \n",
       "2  consumer_electronics             Electronics            NaN   \n",
       "3                    pc      Personal Computers            NaN   \n",
       "4         miscellaneous                   Misc.          ZUKC7   \n",
       "\n",
       "   key_case_pack_quantity key_classification_code  ... cand_pkg_weight  \\\n",
       "0                     NaN            base_product  ...        0.529104   \n",
       "1                     NaN            base_product  ...        0.100000   \n",
       "2                     NaN            base_product  ...        0.654773   \n",
       "3                     NaN            base_product  ...        3.549442   \n",
       "4                     1.0            base_product  ...        0.396832   \n",
       "\n",
       "  cand_pkg_weight_uom  cand_pkg_width cand_release_date_embargo_level  \\\n",
       "0              pounds        5.118110                             NaN   \n",
       "1              pounds        4.500000                             NaN   \n",
       "2              pounds        3.937008                             NaN   \n",
       "3              pounds       10.314961                             NaN   \n",
       "4              pounds        5.196850                             NaN   \n",
       "\n",
       "  cand_dw_creation_date cand_dw_last_updated cand_is_deleted  \\\n",
       "0             18-Apr-13            14-Oct-17               N   \n",
       "1             19-May-16            21-Mar-18               N   \n",
       "2             10-Dec-15            16-Feb-18               N   \n",
       "3             19-Oct-12            15-Feb-18               N   \n",
       "4             26-Jul-12             9-Mar-18               N   \n",
       "\n",
       "  cand_last_updated cand_version  cand_external_testing_certification  \n",
       "0         13-Oct-17         2867                                  NaN  \n",
       "1         20-Mar-18           65                                  NaN  \n",
       "2         15-Feb-18         1532                                  NaN  \n",
       "3         14-Feb-18        13964                                  NaN  \n",
       "4          9-Mar-18         1253                                  NaN  \n",
       "\n",
       "[5 rows x 228 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement here\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>key_Region Id</th>\n",
       "      <th>key_MarketPlace Id</th>\n",
       "      <th>key_ASIN</th>\n",
       "      <th>key_Binding Code</th>\n",
       "      <th>key_binding_description</th>\n",
       "      <th>key_brand_code</th>\n",
       "      <th>key_case_pack_quantity</th>\n",
       "      <th>key_classification_code</th>\n",
       "      <th>key_classification_description</th>\n",
       "      <th>...</th>\n",
       "      <th>cand_pkg_weight</th>\n",
       "      <th>cand_pkg_weight_uom</th>\n",
       "      <th>cand_pkg_width</th>\n",
       "      <th>cand_release_date_embargo_level</th>\n",
       "      <th>cand_dw_creation_date</th>\n",
       "      <th>cand_dw_last_updated</th>\n",
       "      <th>cand_is_deleted</th>\n",
       "      <th>cand_last_updated</th>\n",
       "      <th>cand_version</th>\n",
       "      <th>cand_external_testing_certification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35057</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B0096M8VR2</td>\n",
       "      <td>pc</td>\n",
       "      <td>Personal Computers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>base_product</td>\n",
       "      <td>Base Product</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925932</td>\n",
       "      <td>pounds</td>\n",
       "      <td>5.826772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Apr-13</td>\n",
       "      <td>5-Jul-16</td>\n",
       "      <td>N</td>\n",
       "      <td>4-Jul-16</td>\n",
       "      <td>699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B00EAQJCWW</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>BUNN9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>base_product</td>\n",
       "      <td>Base Product</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17-Mar-16</td>\n",
       "      <td>17-Mar-16</td>\n",
       "      <td>N</td>\n",
       "      <td>17-Mar-16</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B013P93YOQ</td>\n",
       "      <td>toy</td>\n",
       "      <td>Toy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>Base Product</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23-Dec-15</td>\n",
       "      <td>2-Dec-17</td>\n",
       "      <td>N</td>\n",
       "      <td>2-Dec-17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6462</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B00SKJPKGW</td>\n",
       "      <td>wireless_phone_accessory</td>\n",
       "      <td>Wireless Phone Accessory</td>\n",
       "      <td>PIQ22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>base_product</td>\n",
       "      <td>Base Product</td>\n",
       "      <td>...</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>pounds</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22-Jan-15</td>\n",
       "      <td>18-Jan-17</td>\n",
       "      <td>N</td>\n",
       "      <td>18-Jan-17</td>\n",
       "      <td>25351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17533</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B001DCEKXM</td>\n",
       "      <td>sports</td>\n",
       "      <td>Sports</td>\n",
       "      <td>SUUNR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>base_product</td>\n",
       "      <td>Base Product</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176368</td>\n",
       "      <td>pounds</td>\n",
       "      <td>3.228346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4-Jan-11</td>\n",
       "      <td>16-Nov-17</td>\n",
       "      <td>N</td>\n",
       "      <td>16-Nov-17</td>\n",
       "      <td>7424</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  key_Region Id  key_MarketPlace Id    key_ASIN  \\\n",
       "0  35057              1                   1  B0096M8VR2   \n",
       "1  41573              1                   1  B00EAQJCWW   \n",
       "2  44029              1                   1  B013P93YOQ   \n",
       "3   6462              1                   1  B00SKJPKGW   \n",
       "4  17533              1                   1  B001DCEKXM   \n",
       "\n",
       "           key_Binding Code   key_binding_description key_brand_code  \\\n",
       "0                        pc        Personal Computers            NaN   \n",
       "1                   kitchen                   Kitchen          BUNN9   \n",
       "2                       toy                       Toy            NaN   \n",
       "3  wireless_phone_accessory  Wireless Phone Accessory          PIQ22   \n",
       "4                    sports                    Sports          SUUNR   \n",
       "\n",
       "   key_case_pack_quantity key_classification_code  \\\n",
       "0                     1.0            base_product   \n",
       "1                     2.0            base_product   \n",
       "2                     NaN            base_product   \n",
       "3                     1.0            base_product   \n",
       "4                     1.0            base_product   \n",
       "\n",
       "  key_classification_description  ... cand_pkg_weight  cand_pkg_weight_uom  \\\n",
       "0                   Base Product  ...        0.925932               pounds   \n",
       "1                   Base Product  ...             NaN                  NaN   \n",
       "2                   Base Product  ...             NaN                  NaN   \n",
       "3                   Base Product  ...        6.250000               pounds   \n",
       "4                   Base Product  ...        0.176368               pounds   \n",
       "\n",
       "  cand_pkg_width cand_release_date_embargo_level cand_dw_creation_date  \\\n",
       "0       5.826772                             NaN             10-Apr-13   \n",
       "1            NaN                             NaN             17-Mar-16   \n",
       "2            NaN                             NaN             23-Dec-15   \n",
       "3       9.700000                             NaN             22-Jan-15   \n",
       "4       3.228346                             NaN              4-Jan-11   \n",
       "\n",
       "  cand_dw_last_updated cand_is_deleted cand_last_updated  cand_version  \\\n",
       "0             5-Jul-16               N          4-Jul-16           699   \n",
       "1            17-Mar-16               N         17-Mar-16             2   \n",
       "2             2-Dec-17               N          2-Dec-17            17   \n",
       "3            18-Jan-17               N         18-Jan-17         25351   \n",
       "4            16-Nov-17               N         16-Nov-17          7424   \n",
       "\n",
       "   cand_external_testing_certification  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3                                  NaN  \n",
       "4                                  NaN  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement here\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36803 entries, 0 to 36802\n",
      "Columns: 228 entries, ID to cand_external_testing_certification\n",
      "dtypes: float64(90), int64(12), object(126)\n",
      "memory usage: 64.0+ MB\n",
      "\n",
      "Training Dataset Summary Statistics:\n",
      "                 ID         label  key_Region Id  key_MarketPlace Id  \\\n",
      "count  36803.000000  36803.000000        36803.0             36803.0   \n",
      "mean   26341.493438      0.505095            1.0                 1.0   \n",
      "std    15159.339391      0.499981            0.0                 0.0   \n",
      "min        1.000000      0.000000            1.0                 1.0   \n",
      "25%    13250.500000      0.000000            1.0                 1.0   \n",
      "50%    26318.000000      1.000000            1.0                 1.0   \n",
      "75%    39455.500000      1.000000            1.0                 1.0   \n",
      "max    52576.000000      1.000000            1.0                 1.0   \n",
      "\n",
      "       key_case_pack_quantity  key_country_of_origin  key_discontinued_date  \\\n",
      "count            16508.000000                    0.0                    0.0   \n",
      "mean                 9.828326                    NaN                    NaN   \n",
      "std                 72.961235                    NaN                    NaN   \n",
      "min                  0.000000                    NaN                    NaN   \n",
      "25%                  1.000000                    NaN                    NaN   \n",
      "50%                  1.000000                    NaN                    NaN   \n",
      "75%                  6.000000                    NaN                    NaN   \n",
      "max               1700.000000                    NaN                    NaN   \n",
      "\n",
      "            key_ean  key_excluded_direct_browse_node_id  key_fedas_id  ...  \\\n",
      "count  3.338900e+04                        1.013200e+04          33.0  ...   \n",
      "mean   1.704312e+12                        1.931567e+09      100954.0  ...   \n",
      "std    2.406607e+12                        3.543757e+09           0.0  ...   \n",
      "min    1.427901e+07                        1.722820e+05      100954.0  ...   \n",
      "25%    6.464370e+11                        1.064954e+06      100954.0  ...   \n",
      "50%    7.571830e+11                        1.657930e+08      100954.0  ...   \n",
      "75%    8.809600e+11                        2.445458e+09      100954.0  ...   \n",
      "max    9.825480e+12                        1.634073e+10      100954.0  ...   \n",
      "\n",
      "       cand_recall_notice_receive_date  cand_unit_count      cand_upc  \\\n",
      "count                              0.0      4751.000000  2.710200e+04   \n",
      "mean                               NaN        46.670352  6.207103e+11   \n",
      "std                                NaN       746.862227  2.750663e+11   \n",
      "min                                NaN         0.000000  5.012000e+03   \n",
      "25%                                NaN         1.000000  6.134230e+11   \n",
      "50%                                NaN         1.000000  7.157180e+11   \n",
      "75%                                NaN        12.000000  7.938420e+11   \n",
      "max                                NaN     50000.000000  9.999980e+11   \n",
      "\n",
      "       cand_variation_theme_id  cand_video_game_region  cand_pkg_height  \\\n",
      "count             14347.000000               14.000000     29405.000000   \n",
      "mean                 36.932808                1.428571         3.497030   \n",
      "std                  91.314273                0.851631         3.773179   \n",
      "min                   1.000000                1.000000         0.000000   \n",
      "25%                   2.000000                1.000000         1.100000   \n",
      "50%                   8.000000                1.000000         2.400000   \n",
      "75%                  24.000000                1.000000         4.330709   \n",
      "max                1437.000000                3.000000        74.000000   \n",
      "\n",
      "       cand_pkg_length  cand_pkg_weight  cand_pkg_width   cand_version  \n",
      "count     29405.000000     29135.000000    29405.000000   36803.000000  \n",
      "mean         12.478694         5.806474        7.670509   11493.830014  \n",
      "std          11.434224        27.061422        5.980064   75595.969332  \n",
      "min           0.000000         0.000000        0.000000       2.000000  \n",
      "25%           6.300000         0.250000        3.818898      53.000000  \n",
      "50%           9.200000         0.750000        5.905512     195.000000  \n",
      "75%          14.100000         2.802126        9.900000    1175.000000  \n",
      "max         202.400000      2322.000000       97.000000  635453.000000  \n",
      "\n",
      "[8 rows x 102 columns]\n",
      "\n",
      "Missing Values in Training Dataset:\n",
      "ID                                         0\n",
      "label                                      0\n",
      "key_Region Id                              0\n",
      "key_MarketPlace Id                         0\n",
      "key_ASIN                                   0\n",
      "                                       ...  \n",
      "cand_dw_last_updated                       0\n",
      "cand_is_deleted                            0\n",
      "cand_last_updated                          0\n",
      "cand_version                               0\n",
      "cand_external_testing_certification    36226\n",
      "Length: 228, dtype: int64\n",
      "\n",
      "Test Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15774 entries, 0 to 15773\n",
      "Columns: 227 entries, ID to cand_external_testing_certification\n",
      "dtypes: float64(88), int64(11), object(128)\n",
      "memory usage: 27.3+ MB\n",
      "\n",
      "Test Dataset Summary Statistics:\n",
      "                 ID  key_Region Id  key_MarketPlace Id  \\\n",
      "count  15774.000000        15774.0             15774.0   \n",
      "mean   26163.192152            1.0                 1.0   \n",
      "std    15220.590579            0.0                 0.0   \n",
      "min        0.000000            1.0                 1.0   \n",
      "25%    12847.750000            1.0                 1.0   \n",
      "50%    26224.000000            1.0                 1.0   \n",
      "75%    39360.750000            1.0                 1.0   \n",
      "max    52571.000000            1.0                 1.0   \n",
      "\n",
      "       key_case_pack_quantity  key_country_of_origin  key_discontinued_date  \\\n",
      "count             7105.000000                    0.0                    0.0   \n",
      "mean                 9.655313                    NaN                    NaN   \n",
      "std                 68.971566                    NaN                    NaN   \n",
      "min                  0.000000                    NaN                    NaN   \n",
      "25%                  1.000000                    NaN                    NaN   \n",
      "50%                  1.000000                    NaN                    NaN   \n",
      "75%                  6.000000                    NaN                    NaN   \n",
      "max               1700.000000                    NaN                    NaN   \n",
      "\n",
      "            key_ean  key_excluded_direct_browse_node_id  key_fedas_id  \\\n",
      "count  1.433900e+04                        4.304000e+03           7.0   \n",
      "mean   1.694087e+12                        1.857555e+09      100954.0   \n",
      "std    2.382636e+12                        3.462478e+09           0.0   \n",
      "min    1.427901e+07                        1.722820e+05      100954.0   \n",
      "25%    6.464370e+11                        1.064954e+06      100954.0   \n",
      "50%    7.551710e+11                        1.657930e+08      100954.0   \n",
      "75%    8.618530e+11                        2.407760e+09      100954.0   \n",
      "max    9.825480e+12                        1.634073e+10      100954.0   \n",
      "\n",
      "       key_fma_qualified_price_max  ...  cand_recall_notice_receive_date  \\\n",
      "count                 14725.000000  ...                              0.0   \n",
      "mean                    117.616536  ...                              NaN   \n",
      "std                     273.619950  ...                              NaN   \n",
      "min                      10.170000  ...                              NaN   \n",
      "25%                      25.410000  ...                              NaN   \n",
      "50%                      40.790000  ...                              NaN   \n",
      "75%                     102.320000  ...                              NaN   \n",
      "max                    4398.900000  ...                              NaN   \n",
      "\n",
      "       cand_unit_count      cand_upc  cand_variation_theme_id  \\\n",
      "count      2099.000000  1.160000e+04              6122.000000   \n",
      "mean         31.615050  6.190093e+11                35.154851   \n",
      "std         155.009165  2.751171e+11                81.875503   \n",
      "min          -9.000000  2.096700e+05                 1.000000   \n",
      "25%           1.000000  6.134690e+11                 2.000000   \n",
      "50%           1.000000  7.148340e+11                 8.000000   \n",
      "75%          12.000000  7.936310e+11                24.000000   \n",
      "max        5000.000000  9.999990e+11              1364.000000   \n",
      "\n",
      "       cand_video_game_region  cand_pkg_height  cand_pkg_length  \\\n",
      "count                     2.0     12534.000000     12534.000000   \n",
      "mean                      1.0         3.497150        12.503518   \n",
      "std                       0.0         3.725023        11.871577   \n",
      "min                       1.0         0.000000         0.000000   \n",
      "25%                       1.0         1.102362         6.400000   \n",
      "50%                       1.0         2.400000         9.291339   \n",
      "75%                       1.0         4.400000        14.094488   \n",
      "max                       1.0        39.000000       268.110236   \n",
      "\n",
      "       cand_pkg_weight  cand_pkg_width  cand_version  \n",
      "count     12440.000000    12534.000000   15774.00000  \n",
      "mean          5.979049        7.702780   11802.00374  \n",
      "std          26.732522        6.110312   76503.09307  \n",
      "min           0.000000        0.000000       2.00000  \n",
      "25%           0.250000        3.860000      54.00000  \n",
      "50%           0.800000        6.000000     201.00000  \n",
      "75%           2.750000        9.900000    1175.00000  \n",
      "max        1107.000000      109.000000  629101.00000  \n",
      "\n",
      "[8 rows x 99 columns]\n",
      "\n",
      "Missing Values in Test Dataset:\n",
      "ID                                         0\n",
      "key_Region Id                              0\n",
      "key_MarketPlace Id                         0\n",
      "key_ASIN                                   0\n",
      "key_Binding Code                        2017\n",
      "                                       ...  \n",
      "cand_dw_last_updated                       0\n",
      "cand_is_deleted                            0\n",
      "cand_last_updated                          0\n",
      "cand_version                               0\n",
      "cand_external_testing_certification    15515\n",
      "Length: 227, dtype: int64\n",
      "\n",
      "Unique values in key_classification_code:\n",
      "base_product      36607\n",
      "product_bundle      196\n",
      "Name: key_classification_code, dtype: int64\n",
      "\n",
      "Unique values in key_has_ean:\n",
      "Y    33389\n",
      "N     3414\n",
      "Name: key_has_ean, dtype: int64\n",
      "\n",
      "Unique values in key_has_online_play:\n",
      "N    36803\n",
      "Name: key_has_online_play, dtype: int64\n",
      "\n",
      "Unique values in cand_classification_code:\n",
      "base_product         34882\n",
      "variation_parent      1789\n",
      "product_bundle         130\n",
      "collection_parent        1\n",
      "Name: cand_classification_code, dtype: int64\n",
      "\n",
      "Unique values in cand_has_ean:\n",
      "Y    30394\n",
      "N     6409\n",
      "Name: cand_has_ean, dtype: int64\n",
      "\n",
      "Unique values in cand_has_online_play:\n",
      "N    36801\n",
      "Y        2\n",
      "Name: cand_has_online_play, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Implement more EDA here\n",
    "# Print info about the training dataset\n",
    "print(\"Training Dataset Info:\")\n",
    "training_data.info()\n",
    "\n",
    "print(\"\\nTraining Dataset Summary Statistics:\")\n",
    "print(training_data.describe())\n",
    "\n",
    "print(\"\\nMissing Values in Training Dataset:\")\n",
    "print(training_data.isnull().sum())\n",
    "\n",
    "# Print info about the test dataset\n",
    "print(\"\\nTest Dataset Info:\")\n",
    "test_data.info()\n",
    "\n",
    "print(\"\\nTest Dataset Summary Statistics:\")\n",
    "print(test_data.describe())\n",
    "\n",
    "print(\"\\nMissing Values in Test Dataset:\")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Check unique values in categorical columns\n",
    "for col in categorical_features:\n",
    "    print(f\"\\nUnique values in {col}:\")\n",
    "    print(training_data[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset features\n",
    "\n",
    "Let's now print the features of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample text in key_item_name:\n",
      "26433    Dual Output Portable Charger, Oripow Spark A6 ...\n",
      "19451    VALTERRA PRODUCTS, INC. B8202X 2x200' BACKWASH...\n",
      "17251    InstaMagic Hair Straightener Brush with LED Di...\n",
      "25450    Grandma Lucys Freeze-Dried Grain-Free Pet Foo...\n",
      "18666    Underground Toys Star Wars Home Kitchen Storag...\n",
      "Name: key_item_name, dtype: object\n",
      "\n",
      "Sample text in cand_item_name:\n",
      "14862                                 Mighty Wheel Tractor\n",
      "28176    Twin Sized SoundAsleep Dream Series Air Mattre...\n",
      "36648                      Lilax Girls' Racerback Tank Top\n",
      "17588    Pokemon Platinum Rising Rivals #111 Snorlax LV...\n",
      "3011     GOTD 10PC Plastic Nail Art Soak Off Cap Clip U...\n",
      "Name: cand_item_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Implement here\n",
    "\n",
    "# Check sample text in text features\n",
    "for col in text_features:\n",
    "    print(f\"\\nSample text in {col}:\")\n",
    "    print(training_data[col].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 <a name=\"22\">Select features to build the model</a> (Suggested)\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Previously, we recommended using only a few of the numerical features for both key_ and cand_ ASINs: __item_package_quantity__, __item_height__, __item_width__, __item_length__, __item_weight__, __pkg_height__, __pkg_width__, __pkg_length__, __pkg_weight__.\n",
    "\n",
    "We learned how to use __categorical data__ today. Let's select some categorical variables to add to the model, such as __classification_code__, __has_ean__, __has_online_play__.\n",
    "\n",
    "We also discussed text vectorization, so you can include into the model the __item_name__ text fields for example. Feel free to explore other fields from the metadata-dataset.xlsx file. Keep in mind that sklearn expects a seperate transformer for each text field.\n",
    "\n",
    "__Note: Be careful about the missing text values when you are cleaning and stemming your text. Refer to the class exercise: MLA-TAB-DAY2-TREE-MODELS-NB.ipynb.__\n",
    "\n",
    "__Creating Better Features (Optional Extra Hint):__ This is some extra hint if you are interested in reducing your number of features. As we are comparing two products in this problem, it is natural to think about our features as differences of features between the candidate and key products. You can create a new set of features this time looking at the difference between cad. and key features such as: diff_item_height, diff_pkg_weight, diff_classification_code. You can take absolute difference for numerical features or create some binary feature as same or not for categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab model features/inputs and target/output\n",
    "numerical_features = [\"key_item_package_quantity\", \n",
    "                      \"key_item_height\", \"key_item_width\", \"key_item_length\", \"key_item_weight\", \n",
    "                      \"key_pkg_height\", \"key_pkg_width\", \"key_pkg_length\", \"key_pkg_weight\",\n",
    "                      \"cand_item_package_quantity\", \n",
    "                      \"cand_item_height\", \"cand_item_width\", \"cand_item_length\", \"cand_item_weight\", \n",
    "                      \"cand_pkg_height\", \"cand_pkg_width\", \"cand_pkg_length\", \"cand_pkg_weight\"]\n",
    "\n",
    "categorical_features = [\"key_classification_code\", \"key_has_ean\", \"key_has_online_play\", \n",
    "                      \"cand_classification_code\", \"cand_has_ean\", \"cand_has_online_play\"]\n",
    "\n",
    "text_features = [\"key_item_name\", \"cand_item_name\"]\n",
    "\n",
    "model_features = numerical_features + categorical_features + text_features\n",
    "\n",
    "model_target = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 <a name=\"23\">Train - Validation Datasets</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "To monitor network training, use sklearn's [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function on the training set, to get a validation subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (29442, 26)\n",
      "Validation set shape: (7361, 26)\n"
     ]
    }
   ],
   "source": [
    "# Implement here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    training_data[model_features], \n",
    "    training_data[model_target], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 <a name=\"24\">Data processing with Pipeline and ColumnTransformer</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Use the collective ColumnTransformer to process the data for model training, validation, and test, ensuring that the transformations learned on the train data are performed accordingly on the training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training set shape: (29442, 32)\n",
      "Processed validation set shape: (7361, 32)\n",
      "Processed test set shape: (15774, 32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Numerical features processing\n",
    "num_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical features processing\n",
    "cat_processor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine processors (excluding text features)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_processor, numerical_features),\n",
    "    ('cat', cat_processor, categorical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "# Fit the preprocessor and transform the data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(test_data[model_features])\n",
    "\n",
    "print(\"Processed training set shape:\", X_train_processed.shape)\n",
    "print(\"Processed validation set shape:\", X_val_processed.shape)\n",
    "print(\"Processed test set shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Network Training and Validation</a> (Implement)\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Train and validate a neural network with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.6812, Val Loss: 0.6756, Val Accuracy: 0.5753\n",
      "Epoch [2/30], Train Loss: 0.6723, Val Loss: 0.6698, Val Accuracy: 0.5846\n",
      "Epoch [3/30], Train Loss: 0.6678, Val Loss: 0.6699, Val Accuracy: 0.5851\n",
      "Epoch [4/30], Train Loss: 0.6641, Val Loss: 0.6645, Val Accuracy: 0.5937\n",
      "Epoch [5/30], Train Loss: 0.6616, Val Loss: 0.6651, Val Accuracy: 0.5923\n",
      "Epoch [6/30], Train Loss: 0.6600, Val Loss: 0.6633, Val Accuracy: 0.5986\n",
      "Epoch [7/30], Train Loss: 0.6575, Val Loss: 0.6603, Val Accuracy: 0.5992\n",
      "Epoch [8/30], Train Loss: 0.6566, Val Loss: 0.6573, Val Accuracy: 0.6035\n",
      "Epoch [9/30], Train Loss: 0.6542, Val Loss: 0.6593, Val Accuracy: 0.6018\n",
      "Epoch [10/30], Train Loss: 0.6546, Val Loss: 0.6576, Val Accuracy: 0.6040\n",
      "Epoch [11/30], Train Loss: 0.6529, Val Loss: 0.6605, Val Accuracy: 0.5973\n",
      "Epoch [12/30], Train Loss: 0.6520, Val Loss: 0.6601, Val Accuracy: 0.6025\n",
      "Epoch [13/30], Train Loss: 0.6509, Val Loss: 0.6611, Val Accuracy: 0.6037\n",
      "Epoch [14/30], Train Loss: 0.6504, Val Loss: 0.6546, Val Accuracy: 0.6100\n",
      "Epoch [15/30], Train Loss: 0.6489, Val Loss: 0.6560, Val Accuracy: 0.6067\n",
      "Epoch [16/30], Train Loss: 0.6475, Val Loss: 0.6575, Val Accuracy: 0.6039\n",
      "Epoch [17/30], Train Loss: 0.6476, Val Loss: 0.6566, Val Accuracy: 0.6074\n",
      "Epoch [18/30], Train Loss: 0.6458, Val Loss: 0.6589, Val Accuracy: 0.5992\n",
      "Epoch [19/30], Train Loss: 0.6457, Val Loss: 0.6555, Val Accuracy: 0.6128\n",
      "Epoch [20/30], Train Loss: 0.6445, Val Loss: 0.6552, Val Accuracy: 0.6075\n",
      "Epoch [21/30], Train Loss: 0.6438, Val Loss: 0.6550, Val Accuracy: 0.6081\n",
      "Epoch [22/30], Train Loss: 0.6443, Val Loss: 0.6538, Val Accuracy: 0.6102\n",
      "Epoch [23/30], Train Loss: 0.6434, Val Loss: 0.6540, Val Accuracy: 0.6111\n",
      "Epoch [24/30], Train Loss: 0.6411, Val Loss: 0.6579, Val Accuracy: 0.6132\n",
      "Epoch [25/30], Train Loss: 0.6410, Val Loss: 0.6565, Val Accuracy: 0.6086\n",
      "Epoch [26/30], Train Loss: 0.6402, Val Loss: 0.6548, Val Accuracy: 0.6153\n",
      "Epoch [27/30], Train Loss: 0.6391, Val Loss: 0.6566, Val Accuracy: 0.6140\n",
      "Epoch [28/30], Train Loss: 0.6389, Val Loss: 0.6540, Val Accuracy: 0.6115\n",
      "Epoch [29/30], Train Loss: 0.6383, Val Loss: 0.6533, Val Accuracy: 0.6078\n",
      "Epoch [30/30], Train Loss: 0.6369, Val Loss: 0.6542, Val Accuracy: 0.6123\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert processed data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_processed)\n",
    "y_train_tensor = torch.LongTensor(y_train.values)\n",
    "X_val_tensor = torch.FloatTensor(X_val_processed)\n",
    "y_val_tensor = torch.LongTensor(y_val.values)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the neural network\n",
    "class SubstituteNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SubstituteNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SubstituteNet(X_train_tensor.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        _, predicted = torch.max(val_outputs.data, 1)\n",
    "        val_accuracy = (predicted == y_val_tensor).sum().item() / len(y_val_tensor)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Make Predictions on the Test Dataset</a> (Implement)\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Use the trained network to predict the labels on the test set. Test accuracy would be displayed upon a valid submission to the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions made on test dataset.\n",
      "Shape of predictions: (15774,)\n",
      "Shape of probability predictions: (15774, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get test data to test the classifier\n",
    "# Note: test data should come from public_test_features.csv, which we've already loaded as test_data\n",
    "\n",
    "# Convert processed test data to PyTorch tensor\n",
    "X_test_tensor = torch.FloatTensor(X_test_processed)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, test_predictions = torch.max(test_outputs.data, 1)\n",
    "\n",
    "# Convert predictions to numpy array\n",
    "test_predictions = test_predictions.cpu().numpy()\n",
    "\n",
    "print(\"Predictions made on test dataset.\")\n",
    "print(\"Shape of predictions:\", test_predictions.shape)\n",
    "\n",
    "# If you need probabilities instead of class predictions\n",
    "test_probabilities = torch.softmax(test_outputs, dim=1).cpu().numpy()\n",
    "print(\"Shape of probability predictions:\", test_probabilities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Write the test predictions to a CSV file</a> (Given)\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Use the following code to write the test predictions to a CSV file. Download locally the CSV file from the SageMaker instance, and upload it to __https://mlu.corp.amazon.com/contests/redirect/35__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\"ID\", \"label\"])\n",
    "result_df[\"ID\"] = test_data[\"ID\"].tolist()\n",
    "result_df[\"label\"] = test_predictions\n",
    "\n",
    "result_df.to_csv(\"../../data/final_project/project_day3_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double-check submission file against the sample_submission.csv\n",
      "Differences between project_day3_result IDs and sample submission IDs: 0\n"
     ]
    }
   ],
   "source": [
    "print('Double-check submission file against the sample_submission.csv')\n",
    "sample_submission_df = pd.read_csv('../../data/final_project/sample-submission.csv')\n",
    "print('Differences between project_day3_result IDs and sample submission IDs:',(sample_submission_df['ID'] != result_df['ID']).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
